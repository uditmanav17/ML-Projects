{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Delivery prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import missingno as msno\n",
    "from geopy.distance import geodesic\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "print(f\"Rows/columns dimension - {df.shape}\")\n",
    "print(\"Data types - \")\n",
    "print(df.dtypes)\n",
    "print(\"Columns - \")\n",
    "print(df.columns)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delivery person ID contains city_code\n",
    "df[\"city_code\"] = df['Delivery_person_ID'].str.split(\"RES\", expand=True)[0]\n",
    "\n",
    "# remove unique identifiers\n",
    "df.drop(columns=[\"ID\", \"Delivery_person_ID\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"Delivery_person_Age\": \"driver_age\",\n",
    "        \"Delivery_person_Ratings\": \"driver_rating\",\n",
    "        \"Restaurant_latitude\": \"restaurant_lat\",\n",
    "        \"Restaurant_longitude\": \"restaurant_long\",\n",
    "        \"Delivery_location_latitude\": \"dest_location_lat\",\n",
    "        \"Delivery_location_longitude\": \"dest_location_long\",\n",
    "        \"Order_Date\": \"order_date\",\n",
    "        \"Time_Orderd\": \"time_ordered\",\n",
    "        \"Time_Order_picked\": \"time_order_picked\",\n",
    "        \"Weatherconditions\": \"weather\",\n",
    "        \"Road_traffic_density\": \"traffic_density\",\n",
    "        \"Vehicle_condition\": \"vehicle_condition\",\n",
    "        \"Type_of_order\": \"order_type\",\n",
    "        \"Type_of_vehicle\": \"vehicle_type\",\n",
    "        # 'multiple_deliveries': \"multiple_deliveries\",\n",
    "        \"Festival\": \"festival\",\n",
    "        \"City\": \"city\",\n",
    "        \"Time_taken(min)\": \"time_taken_min\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `NaN` values present in some columns as string\n",
    "- additional features can be included like -\n",
    "    - food_prep_time = order_ime - picked_time\n",
    "    - distance = dest_lat_long - restaurant_lat_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking columns datatypes and their unique values\n",
    "for col in df.columns:\n",
    "    uniques = df[col].nunique()\n",
    "    print(f\"# unique in {col} \\t- {uniques}\")\n",
    "    if uniques < 25:\n",
    "        print(\"\\t\\t\", df[col].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and convert missing to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking NA\n",
    "df.replace('NaN', float(np.nan), regex=True,inplace=True)\n",
    "\n",
    "display(df.isna().sum())\n",
    "\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes\n",
    "df['driver_age'] = df['driver_age'].astype('float64')\n",
    "df['driver_rating'] = df['driver_rating'].astype('float64')\n",
    "df['multiple_deliveries'] = df['multiple_deliveries'].astype('float64')\n",
    "df['order_date'] = pd.to_datetime(df['order_date'],format=\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values\n",
    "# - imputing missing values\n",
    "# - dropping rows having missing features\n",
    "# since we have very few missing features and good amouint of data, we'll go with dropping rows\n",
    "df2 = df.dropna(how=\"any\")\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"../data/train_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned data\n",
    "df = pd.read_csv(\n",
    "    \"../data/train_cleaned.csv\",\n",
    "    parse_dates=[\"order_date\"], # , \"time_ordered\", \"time_order_picked\"\n",
    "    date_format=\"%Y-%m-%d\"\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create additional features\n",
    "# df = 0\n",
    "df[\"weekend\"] = df[\"order_date\"].dt.day_of_week > 4\n",
    "\n",
    "df[\"month_intervals\"] = df[\"order_date\"].apply(lambda x:\n",
    "                                                \"start_month\" if x.day <=10\n",
    "                                                else (\"middle_month\" if x.day <= 20 else \"end_month\")\n",
    "                                            )\n",
    "\n",
    "df[\"year_quarter\"] = df[\"order_date\"].apply(lambda x: x.quarter)\n",
    "\n",
    "# Calculate formatted pickup time considering cases where pickup time is on the next day\n",
    "df['time_order_picked_formatted'] = (\n",
    "    df['order_date']\n",
    "    + pd.to_timedelta(np.where(df['time_order_picked'] < df['time_ordered'], 1, 0), unit='D')\n",
    "    + pd.to_timedelta(df['time_order_picked'])\n",
    ")\n",
    "\n",
    "# Calculate formatted order time\n",
    "df['time_ordered_formatted'] = df['order_date'] + pd.to_timedelta(df['time_ordered'])\n",
    "\n",
    "# Calculate time difference in minutes\n",
    "df['order_prepare_time'] = (df['time_order_picked_formatted'] - df['time_ordered_formatted']).dt.total_seconds() / 60\n",
    "\n",
    "# Handle null values by filling with the median\n",
    "df['order_prepare_time'].fillna(df['order_prepare_time'].median(), inplace=True)\n",
    "\n",
    "# remove redundant columns\n",
    "df.drop(['time_ordered', 'time_order_picked', 'time_ordered_formatted', 'time_order_picked_formatted', 'order_date'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 6371  ##The earth's radius (in km)\n",
    "\n",
    "def deg_to_rad(degrees):\n",
    "    return degrees * (np.pi/180)\n",
    "\n",
    "## The haversine formula\n",
    "def distcalculate(lat1, lon1, lat2, lon2):\n",
    "    d_lat = deg_to_rad(lat2-lat1)\n",
    "    d_lon = deg_to_rad(lon2-lon1)\n",
    "    a1 = np.sin(d_lat/2)**2 + np.cos(deg_to_rad(lat1))\n",
    "    a2 = np.cos(deg_to_rad(lat2)) * np.sin(d_lon/2)**2\n",
    "    a = a1 * a2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "# Create distance column & calculate the distance\n",
    "df['distance'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "  df.loc[i, 'distance'] = distcalculate(df.loc[i, 'restaurant_lat'],\n",
    "                                          df.loc[i, 'restaurant_long'],\n",
    "                                          df.loc[i, 'dest_location_lat'],\n",
    "                                          df.loc[i, 'dest_location_long'])\n",
    "df.distance = df.distance.astype(\"int64\")\n",
    "df.distance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weather\"] = df[\"weather\"].str.lower().str.split(expand=True)[1]\n",
    "df[\"time_taken_min\"] = df[\"time_taken_min\"].str.lower().str.split(expand=True)[1]\n",
    "df[\"time_taken_min\"] = df[\"time_taken_min\"].str.strip().astype(int)\n",
    "df[\"festival\"] = df[\"festival\"] == \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/train_feature_engineered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance vs time taken\n",
    "figure = px.scatter(data_frame = df,\n",
    "                    x=\"distance\",\n",
    "                    y=\"time_taken_min\",\n",
    "                    size=\"time_taken_min\",\n",
    "                    trendline=\"ols\",\n",
    "                    title = \"Relationship Between Time Taken and Distance\")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver age vs distance\n",
    "figure = px.scatter(data_frame = df,\n",
    "                    x=\"driver_age\",\n",
    "                    y=\"time_taken_min\",\n",
    "                    size=\"time_taken_min\",\n",
    "                    color = \"distance\",\n",
    "                    trendline=\"ols\",\n",
    "                    title = \"Relationship Between Delivery Partner Age and Time Taken\")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating vs time taken\n",
    "figure = px.scatter(data_frame = df,\n",
    "                    x=\"driver_rating\",\n",
    "                    y=\"time_taken_min\",\n",
    "                    size=\"time_taken_min\",\n",
    "                    color = \"distance\",\n",
    "                    trendline=\"ols\",\n",
    "                    title = \"Relationship Between Delivery Partner Ratings and Time Taken\")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_type vs time vs order type\n",
    "fig = px.box(df,\n",
    "             x=\"vehicle_type\",\n",
    "             y=\"time_taken_min\",\n",
    "             color=\"order_type\",\n",
    "             title = \"Relationship Between Type of Vehicle and Type of Order\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train_feature_engineered.csv\", index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical features\n",
    "categorical_columns = df.select_dtypes(include='object').columns\n",
    "label_encoder = LabelEncoder()\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda col: label_encoder.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {column_name: idx for idx, column_name in enumerate(df.columns)}\n",
    "column_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features & label\n",
    "X = df.drop('time_taken_min', axis=1)\n",
    "y = df['time_taken_min']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Perform standardization on the training data\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Perform standardization on the testing data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Try different models with hyperparameter tuning using grid/random search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    xgb.XGBRegressor(),         # Random Forest regressor with XGBoost (Gradient Boosting Trees)\n",
    "\n",
    "    # optional\n",
    "    # LGBMRegressor(),          # Light Gradient Boost Regressor\n",
    "    # CatBoostRegressor()       # Cat Boost Regressor\n",
    "]\n",
    "\n",
    "param_grid = [\n",
    "    {},\n",
    "    {'max_depth': [3, 5, 7]},\n",
    "    {'n_estimators': [3, 5, 7], 'max_features': ['sqrt', 'log2']},                          # to reduce training time\n",
    "                                                                                                    # {'n_estimators': [100, 200, 300]}, # more training time\n",
    "\n",
    "    {'n_estimators': [20, 25, 30], 'max_depth': [5, 7, 9]},                                         # xgb params\n",
    "\n",
    "    # {'num_leaves': [15, 20, 5], 'max_depth': [3, 5, 8], 'learning_rate': [0.05, 0.1, 0.2]},       # 'num_leaves': [85]\n",
    "    # {'n_estimators': [5, 7, 9], 'max_depth': [6, 8, 10], 'learning_rate': [0.05, 0.1, 0.2]}       # experiment with 'n_estimators': [500, 700, 900]\n",
    "]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    grid_search = GridSearchCV(model, param_grid[i], cv=5, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"{model.__class__.__name__}:\")\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best R2 score:\", grid_search.best_score_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain best regressor from scratch\n",
    "# Create a XGB regressor model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=20 ,max_depth=7)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation using adjusted r2\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "def adjusted_r_squared(r2, n, k):\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "adjusted_r2 = adjusted_r_squared(r2, len(y_test), X_test.shape[1])\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,2))\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,2))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,2))\n",
    "print(\"R-squared (R2) Score:\", round(r2,2))\n",
    "print(\"Adjusted R-squared Score:\", round(adjusted_r2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection - forward selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "sfs = SFS(xgb.XGBRegressor(n_estimators=20,max_depth=7),\n",
    "           k_features=\"best\",\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=2)\n",
    "\n",
    "sfs = sfs.fit(X_train ,y_train)\n",
    "selected_feat_= list(sfs.k_feature_names_)\n",
    "selected_feat_ = list(map(int, selected_feat_))\n",
    "\n",
    "selected_feat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    # 'Delivery_person_Age', 'Delivery_person_Ratings', 'Weather_conditions', 'month_intervals', 'year_quarter',\n",
    "    # 'Road_traffic_density', 'Vehicle_condition', 'Multiple_deliveries', 'Festival', 'City_type', \"is_weekend\",\n",
    "    \"driver_rating\", \"weather\", \"traffic_density\", \"vehicle_condition\",\n",
    "    \"vehicle_type\", \"multiple_deliveries\", \"city\", \"order_prepare_time\",\n",
    "]\n",
    "\n",
    "X_train = df[selected_columns]         # Features\n",
    "y = df['time_taken_min']              # Target variable\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()                    # Create a StandardScaler object\n",
    "scaler.fit(X_train)                          # Fit the scaler on the training data\n",
    "X_train = scaler.transform(X_train)          # Perform standardization on the training data\n",
    "X_test = scaler.transform(X_test)            # Perform standardization on the testing data\n",
    "\n",
    "\n",
    "# Fit XGBRegressor model with selected features\n",
    "model = xgb.XGBRegressor(n_estimators=20, max_depth=7)  # Initialize XGBRegressor model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions with selected features and seeing if accuracy improved or not of the model\n",
    "xgb_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "def adjusted_r_squared(r2, n, k):\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, xgb_pred)\n",
    "mse = mean_squared_error(y_test, xgb_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, xgb_pred)\n",
    "adjusted_r2 = adjusted_r_squared(r2, len(y_test), X_test.shape[1])\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,2))\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,2))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,2))\n",
    "print(\"R-squared (R2) Score:\", round(r2,2))\n",
    "print(\"Adjusted R-squared Score:\", round(adjusted_r2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  feature selection - backward elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop('time_taken_min', axis=1)  # Features\n",
    "y = df['time_taken_min']  # Target variable\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()                    # Create a StandardScaler object\n",
    "scaler.fit(X_train)                          # Fit the scaler on the training data\n",
    "X_train_scaled = scaler.transform(X_train)   # Perform standardization on the training data\n",
    "X_test_scaled = scaler.transform(X_test)     # Perform standardization on the testing data\n",
    "\n",
    "# Initialize XGBRegressor model as the base model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=20, max_depth=9)\n",
    "\n",
    "# Define the number of features to select\n",
    "num_features_list = [7, 11, 15, 18, 20]\n",
    "\n",
    "feature_names = X.columns  # Get the feature names from the DataFrame\n",
    "\n",
    "for num_features in num_features_list:\n",
    "\n",
    "    # Initialize RFE with the model and the number of features to select\n",
    "    rfe = RFE(estimator=xgb_model, n_features_to_select=num_features)\n",
    "\n",
    "    # Fit RFE to the training data\n",
    "    rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Get the ranking of each feature\n",
    "    feature_ranking = rfe.ranking_\n",
    "\n",
    "    # Get the indices of the selected features\n",
    "    selected_features_indices = np.where(feature_ranking == 1)[0]\n",
    "\n",
    "    # Map the selected indices back to the feature names\n",
    "    selected_feature_names = feature_names[selected_features_indices]\n",
    "\n",
    "    # Visualize the feature ranking\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.title(f\"RFE - Feature Ranking for {num_features} Features\")\n",
    "    plt.xlabel(\"Feature Index\")\n",
    "    plt.ylabel(\"Ranking\")\n",
    "    plt.xticks(range(len(feature_ranking)), np.arange(1, len(feature_ranking) + 1))\n",
    "    plt.bar(range(len(feature_ranking)), feature_ranking)\n",
    "    plt.show()\n",
    "\n",
    "    # Print the selected features\n",
    "    print(f\"Selected {num_features} Features:\", selected_feature_names)\n",
    "\n",
    "    # Train the final model using the selected features\n",
    "    xgb_model.fit(X_train_scaled[:, selected_features_indices], y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    accuracy = xgb_model.score(X_test_scaled[:, selected_features_indices], y_test)\n",
    "    print(\"Accuracy on the Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting 7 features (by backward elimination) will yeild same accuracy as Xgboost model `~0.72`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q matplotlib\n",
    "# !pip install -q plotly\n",
    "# !pip install -q ydata-profiling\n",
    "# !pip install -q -U nbformat\n",
    "# !pip install -q --upgrade pip setuptools\n",
    "# !pip install -q --force-reinstall nbformat\n",
    "!pip install -q prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"../data/PJME_hourly.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "df.sort_values(by=['Datetime'], axis=0, ascending=True, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.rename(columns={'PJME_MW':'demand_in_MW'}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"duplicates -\", df.duplicated(subset=\"Datetime\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='Datetime', keep='last', inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if we have a continuous dataset\n",
    "df = df.set_index('Datetime')\n",
    "print(f'df.index.freq is set to: {df.index.freq}')\n",
    "\n",
    "# The fact our datetime index's frequency is set to None is an indication there are some missing data points\n",
    "# somewhere (otherwise Python could deduce it). Let's compare it to an uninterruped custom date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=min(df.index),\n",
    "                           end=max(df.index),\n",
    "                           freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The difference in length between the custom date range and our dataset is {(len(date_range)-len(df))}:')\n",
    "print(date_range.difference(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will append the previously missing datetimes, and create null values in our target variable\n",
    "df = df.reindex(date_range)\n",
    "\n",
    "# we fill in the blanks with values that lie on a linear curve between existing data points\n",
    "df['demand_in_MW'].interpolate(method='linear', inplace=True)\n",
    "\n",
    "# now we have a neatly continuous datetime index\n",
    "print(f'The df.index.freq is now: {df.index.freq}, indicating that we no longer have missing instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dow'] = df.index.dayofweek\n",
    "df['doy'] = df.index.dayofyear\n",
    "df['year'] = df.index.year\n",
    "df['month'] = df.index.month\n",
    "df['quarter'] = df.index.quarter\n",
    "df['hour'] = df.index.hour\n",
    "df['weekday'] = df.index.weekday\n",
    "df['woy'] = df.index.isocalendar().week\n",
    "df['dom'] = df.index.day\n",
    "df['date'] = df.index.date\n",
    "\n",
    "# let's add the season number\n",
    "df['season'] = df['month'].apply(lambda month_number: (month_number % 12 + 3)//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_and_time'] = df.index\n",
    "\n",
    "# plotting\n",
    "fig = px.line(df,\n",
    "              x='date_and_time',\n",
    "              y='demand_in_MW',\n",
    "              title=f'Power Demand (MW) over time [{min(df.year)} - {max(df.year)}]')\n",
    "fig.update_traces(line=dict(width=0.05))\n",
    "fig.update_layout(xaxis_title='Date & Time (yyyy/mm/dd hh:MM)',\n",
    "                  yaxis_title='Energy Demand [MW]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power demand throughout the day for each weekday\n",
    "\n",
    "# aggregated data\n",
    "grouped_data = (\n",
    "    df\n",
    "    .groupby(['hour', 'weekday'], as_index=False)\n",
    "    .agg({'demand_in_MW':'median'})\n",
    ")\n",
    "\n",
    "# plotting\n",
    "fig = px.line(grouped_data,\n",
    "              x='hour',\n",
    "              y='demand_in_MW',\n",
    "              color='weekday',\n",
    "              title='Median Hourly Power Demand per Weekday')\n",
    "fig.update_layout(xaxis_title='Hour',\n",
    "                  yaxis_title='Energy Demand [MW]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated data\n",
    "grouped_data2 = (\n",
    "    df\n",
    "    .groupby(['hour', 'season'], as_index=False)\\\n",
    "    .agg({'demand_in_MW':'median'})\n",
    ")\n",
    "\n",
    "# plotting\n",
    "fig = px.line(grouped_data2,\n",
    "              x='hour',\n",
    "              y='demand_in_MW',\n",
    "              color='season',\n",
    "              title='Median Hourly Power Demand per Season')\n",
    "fig.update_layout(xaxis_title='Hour',\n",
    "                  yaxis_title='Energy Demand [MW]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# seasonal_decompose needs a dataframe with a datetime index\n",
    "series = df[['demand_in_MW']]\n",
    "frequency = 24*365\n",
    "\n",
    "# decomposing the time-series, with the frequency being 24 hours per 365 days\n",
    "decomposed = seasonal_decompose(series, model='additive',period=frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a line plot of the data\n",
    "fig = px.line(decomposed.trend,\n",
    "        y=\"trend\",\n",
    "        title=\"Trend\",\n",
    "        height=300)\n",
    "\n",
    "# adjust line width\n",
    "fig.update_traces(line=dict(width=2))\n",
    "\n",
    "# change layout of axes and the figure's margins\n",
    "# to emulate tight_layout\n",
    "fig.update_layout(\n",
    "        xaxis=dict(\n",
    "        showticklabels=False,\n",
    "        linewidth=1\n",
    "        ),\n",
    "        yaxis=dict(title=''),\n",
    "        margin=go.layout.Margin(\n",
    "            l=40, r=40, b=0, t=40, pad=0\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# display\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(decomposed.seasonal,\n",
    "        y=\"seasonal\",\n",
    "        title=\"Seasonality\",\n",
    "        height=300)\n",
    "\n",
    "fig.update_traces(line=dict(width=0.025))\n",
    "\n",
    "fig.update_layout(\n",
    "        xaxis=dict(\n",
    "        showticklabels=False,\n",
    "        linewidth=1\n",
    "        ),\n",
    "        yaxis=dict(title=''),\n",
    "        margin=go.layout.Margin(\n",
    "            l=40, r=40, b=0, t=40, pad=0\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(decomposed.resid,\n",
    "        y=\"resid\",\n",
    "        title=\"Residuals\",\n",
    "        height=300)\n",
    "\n",
    "fig.update_traces(line=dict(width=0.5))\n",
    "\n",
    "fig.update_layout(\n",
    "        xaxis=dict(\n",
    "        showticklabels=False,\n",
    "        linewidth=1\n",
    "        ),\n",
    "        yaxis=dict(title=''),\n",
    "        margin=go.layout.Margin(\n",
    "            l=40, r=40, b=0, t=40, pad=0\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The last date time point in our dataframe is: {max(df.index)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cutoff date manually\n",
    "CUTOFF_DATE = pd.to_datetime('2017-08-01')\n",
    "TIME_DELTA = pd.DateOffset(years=8)\n",
    "\n",
    "# splitting\n",
    "train = df.loc[(df.index < CUTOFF_DATE) & (df.index >= CUTOFF_DATE-TIME_DELTA) ].copy()\n",
    "test = df.loc[df.index >= CUTOFF_DATE].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training shape: {train.shape} \\nTesting shape: {test.shape}\\n')\n",
    "print(f'The training set lies between the dates: {min(train.index)} and {max(train.index)}')\n",
    "print(f'For the testing set, the dates are: {min(test.index)} and {max(test.index)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Holt Winters - Triple exponential smoothning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential smoothing only takes into consideration patterns in the target variable\n",
    "# so we discard the other features\n",
    "exp_smooth_train, exp_smooth_test = train['demand_in_MW'], test['demand_in_MW']\n",
    "\n",
    "# fit & predict\n",
    "holt_winter = sm.tsa.ExponentialSmoothing(exp_smooth_train,\n",
    "                                          seasonal_periods=24*365,\n",
    "                                          seasonal='add').fit()\n",
    "y_hat_holt_winter = holt_winter.forecast(len(exp_smooth_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'holt_winter_model.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(holt_winter, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_smooth_train, exp_smooth_test = train['demand_in_MW'], test['demand_in_MW']\n",
    "\n",
    "# To load the model later\n",
    "with open(\"holt_winter_model.pkl\", 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "y_hat_holt_winter = loaded_model.forecast(len(exp_smooth_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=exp_smooth_test.index, y=exp_smooth_test,\n",
    "                         mode='lines',\n",
    "                         name='Test - Ground Truth'))\n",
    "fig.add_trace(go.Scatter(x=y_hat_holt_winter.index, y=y_hat_holt_winter,\n",
    "                         mode='lines',\n",
    "                         name='Test - Prediction'))\n",
    "\n",
    "# adjust layout\n",
    "fig.update_traces(line=dict(width=0.5))\n",
    "fig.update_layout(title='Holt-Winter Forecast of Hourly Energy Demand',\n",
    "                  xaxis_title='Date & Time (yyyy/mm/dd hh:MM)',\n",
    "                  yaxis_title='Energy Demand [MW]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    \"\"\" Mean Absolute Percentage Error \"\"\"\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    # take the percentage error\n",
    "    pe = (y_true - y_pred) / y_true\n",
    "\n",
    "    # take the absolute values\n",
    "    ape = np.abs(pe)\n",
    "\n",
    "    # quantify the performance in a single number\n",
    "    mape = np.mean(ape)\n",
    "\n",
    "    return f'{mape*100:.2f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_hw = mape(y_true=exp_smooth_test, y_pred=y_hat_holt_winter)\n",
    "print(f'Our Holt-Winter model has a mean average percentage error of {mape_hw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter day predictions\n",
    "\n",
    "# interval length\n",
    "interval = 24 * 7\n",
    "\n",
    "# intermediary variables for readability\n",
    "x_true, y_true = exp_smooth_test.iloc[:interval].index, exp_smooth_test.iloc[:interval]\n",
    "x_pred, y_pred = y_hat_holt_winter.iloc[:interval].index, y_hat_holt_winter.iloc[:interval]\n",
    "\n",
    "# create figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_true, y=y_true,\n",
    "                         mode='lines',\n",
    "                         name='Test - Ground Truth'))\n",
    "fig.add_trace(go.Scatter(x=x_pred, y=y_pred,\n",
    "                         mode='lines',\n",
    "                         name='Test - Prediction'))\n",
    "\n",
    "# adjust layout\n",
    "fig.update_traces(line=dict(width=0.9))\n",
    "fig.update_layout(title=f'Holt-Winter Intra-Day Forecast of First {interval} Hours of Energy Demand',\n",
    "                  xaxis_title='Date & Time (yyyy/mm/dd hh:MM)',\n",
    "                  yaxis_title='Energy Demand [MW]')\n",
    "fig.show()\n",
    "\n",
    "# quantify accuracy\n",
    "print(f'MAPE for interval of the first {interval} hours: {mape(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval length\n",
    "interval = -24 * 7\n",
    "\n",
    "# intermediary variables for readability\n",
    "x_true, y_true = exp_smooth_test.iloc[interval:].index, exp_smooth_test.iloc[interval:]\n",
    "x_pred, y_pred = y_hat_holt_winter.iloc[interval:].index, y_hat_holt_winter.iloc[interval:]\n",
    "\n",
    "# create figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_true, y=y_true,\n",
    "                         mode='lines',\n",
    "                         name='Test - Ground Truth'))\n",
    "fig.add_trace(go.Scatter(x=x_pred, y=y_pred,\n",
    "                         mode='lines',\n",
    "                         name='Test - Prediction'))\n",
    "\n",
    "# adjust layout\n",
    "fig.update_traces(line=dict(width=0.9))\n",
    "fig.update_layout(title=f'Holt-Winter Intra-Day Forecast of Last {abs(interval)} Hours of Energy Demand',\n",
    "                  xaxis_title='Date & Time (yyyy/mm/dd hh:MM)',\n",
    "                  yaxis_title='Energy Demand [MW]')\n",
    "fig.show()\n",
    "\n",
    "# quantify accuracy\n",
    "print(f'MAPE for interval of the last {abs(interval)} hours: {mape(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use tra.diff()(differenced data), because this time series is unit root process.\n",
    "# ACF and PACF - partial auto correlation\n",
    "fig,ax = plt.subplots(2,1,figsize=(20,10))\n",
    "fig = sm.graphics.tsa.plot_acf( train['demand_in_MW'].diff().dropna(), lags=72, ax=ax[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(train['demand_in_MW'].diff().dropna(), lags=72, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_train = train.reset_index(drop=True)\n",
    "prophet_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_train.rename({\"date_and_time\":\"ds\",\"demand_in_MW\":\"y\"},axis=1,inplace=True)\n",
    "prophet_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment this column for multivariate time series analysis\n",
    "\n",
    "prophet_train.drop(\n",
    "    columns=[\"dow\",\"doy\",\"year\",\"month\",\"quarter\",\"hour\",\"weekday\",\"woy\",\"dom\",\"date\",\"season\"],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_test = test.reset_index(drop=True)\n",
    "prophet_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_test.rename({\"date_and_time\":\"ds\",\"demand_in_MW\":\"y\"},axis=1,inplace=True)\n",
    "prophet_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_test.drop(\n",
    "    columns=[\"dow\",\"doy\",\"year\",\"month\",\"quarter\",\"hour\",\"weekday\",\"woy\",\"dom\",\"date\",\"season\"],\n",
    "    axis=1, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet model training\n",
    "\n",
    "# Importing Prophet\n",
    "from prophet import Prophet\n",
    "\n",
    "\n",
    "# Instantiate the Prophet model\n",
    "prophet_model = Prophet()\n",
    "\n",
    "# Fit the model to the training data\n",
    "prophet_model.fit(prophet_train)\n",
    "\n",
    "# Make future predictions\n",
    "future = prophet_model.make_future_dataframe(periods=len(prophet_test), freq='H')\n",
    "forecast = prophet_model.predict(future)\n",
    "\n",
    "# Extracting predictions for the test period\n",
    "y_hat_prophet = forecast[-len(prophet_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_prophet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=prophet_test[\"ds\"], y=prophet_test[\"y\"],\n",
    "                         mode='lines',\n",
    "                         name='Test - Ground Truth'))\n",
    "fig.add_trace(go.Scatter(x=y_hat_prophet[\"ds\"], y=y_hat_prophet[\"yhat\"],\n",
    "                         mode='lines',\n",
    "                         name='Test - Prediction'))\n",
    "\n",
    "fig.update_traces(line=dict(width=0.5))\n",
    "fig.update_layout(title='Prophet Forecast of Hourly Energy Demand',\n",
    "                  xaxis_title='Date & Time (yyyy/mm/dd hh:MM)',\n",
    "                  yaxis_title='Energy Demand [MW]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'prophet_model.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(prophet_model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
